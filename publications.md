---
layout: page
title: ""
---

## PhD Thesis ##
**E. Loweimi**, "[Robust Phase-based Speech Signal Processing: From Source-Filter Separation to Model-Based Robust ASR](https://etheses.whiterose.ac.uk/19409)" Ph.D. thesis, University of Sheffield, 2018. &nbsp; &nbsp; [PDF](https://etheses.whiterose.ac.uk/19409/1/Erfan_Loweimi_PhD_Thesis.pdf) &nbsp; &nbsp; [BibTeX](/files/others/phd-thesis.bib) &nbsp; &nbsp;
<br>

## Journals ##

1. **E. Loweimi**, Z. Yue, P. Bell, S. Renals, and Z. Cvetkovic, “[Multi-stream Acoustic
Modelling using Raw Real and Imaginary Parts of the Fourier Transform](https://ieeexplore.ieee.org/abstract/document/10026604)”, in IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 31, pp. 876-890, 2023, doi: 10.1109/TASLP.2023.3237167.

2. Z. Yue **<sup>&#8224;</sup>, E. Loweimi <sup>&#8224;</sup>**, J. Barker, H. Christensen, and Z. Cvetkovic, “[Acoustic
Modelling from Raw Source and Filter Components for Dysarthric Speech Recognition](https://ieeexplore.ieee.org/document/9900378)”,
in IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 30, pp. 2968-2980, 2022, doi: 10.1109/TASLP.2022.3205766.
(**<sup>&#8224;</sup>** Equal contribution).

<br>

## Conferences ##

1. Z. Yue **<sup>&#8224;</sup>, E. Loweimi <sup>&#8224;</sup>**, and Z. Cvetkovic, “[Dysarthric speech recognition, detection and classification using raw phase and magnitude spectra](https://kclpure.kcl.ac.uk/portal/en/publications/dysarthric-speech-recognition-detection-and-classification-using-)“, INTERSPEECH, 2023 (**<sup>&#8224;</sup>** Equal contribution).

2. Z. Yue **<sup>&#8224;</sup>, E. Loweimi <sup>&#8224;</sup>**, J. Barker, H. Christensen, and Z. Cvetkovic, “[Dysarthric Speech Recognition from Raw Waveform with Parametric CNNs](https://www.isca-speech.org/archive/interspeech_2022/yue22_interspeech.html)”, INTERSPEECH,
2022 (**<sup>&#8224;</sup>** Equal contribution).

3. N. Shao, **E. Loweimi**, and X. Li, “[RCT: Random Consistency Training for Semisupervised Sound Event Detection](https://www.isca-speech.org/archive/interspeech_2022/shao22_interspeech.html)”, INTERSPEECH, 2022.

4. Z. Yue **<sup>&#8224;</sup>, E. Loweimi<sup>&#8224;</sup>**, and Z. Cvetkovic, “[Raw Source and Filter Modelling for Dysarthric Speech Recognition](https://ieeexplore.ieee.org/document/9746553)”, ICASSP, 2022 (**<sup>&#8224;</sup>** Equal contribution).

5. Z. Yue, **E. Loweimi**, Z. Cvetkovic, H. Christensen, and J. Barker, “[Multimodal Acoustic-Articulatory Feature Fusion for Dysarthric Speech Recognition](https://ieeexplore.ieee.org/document/9746855)”, ICASSP, 2022.

6. **E. Loweimi**, P. Bell, and S. Renals, “[Speech Acoustic Modelling using Raw Source and Filter Components](https://www.isca-speech.org/archive/interspeech_2021/loweimi21_interspeech.html)”, INTERSPEECH, 2021.

7. S. Zhang, **E. Loweimi**, P. Bell, and S. Renals, “[Stochastic Attention Head Removal: A Simple and Effective Method for Improving Transformer Based ASR
Models](https://www.isca-speech.org/archive/interspeech_2021/zhang21p_interspeech.html)”, INTERSPEECH, 2021.

8. **E. Loweimi**, Z. Cvetkovic, P. Bell, and S. Renals, “[Speech Acoustic Modelling from Raw Phase Spectrum](https://ieeexplore.ieee.org/document/9413727)”, ICASSP, 2021.

9. S. Zhang, C-T. Do, R. Doddipatla, **E. Loweimi**, P. Bell, and S. Renals, “[Train Your Classifier First: Cascade Neural Networks Training from Upper Layers to Lower Layers](https://ieeexplore.ieee.org/document/9413565)”, ICASSP, 2021.

10. **E. Loweimi**, P. Bell, and S. Renals, “[Raw Sign and Magnitude Spectra for Multihead Acoustic Modelling](https://www.isca-speech.org/archive/interspeech_2020/loweimi20b_interspeech.html)”, INTERSPEECH, 2020.

11. **E. Loweimi**, P. Bell, and S. Renals, “[On the Robustness and Training Dynamics of Raw Waveform Models](https://www.isca-speech.org/archive/interspeech_2020/loweimi20_interspeech.html)”, INTERSPEECH, 2020.

12. S. Zhang, **E. Loweimi**, P. Bell, and S. Renals, “[On The Usefulness of Self-Attention for Automatic Speech Recognition with Transformers](https://ieeexplore.ieee.org/abstract/document/9383521))”, SLT, 2020.

13. J. Fainberg, O. Klejch, **E. Loweimi**, P. Bell, and S. Renals, “[Acoustic Model Adaptation from Raw Waveforms with SincNet](https://ieeexplore.ieee.org/document/9003974)”, ASRU, 2019.

14. **E. Loweimi**, P. Bell, and S. Renals, “[On Learning Interpretable CNNs with Parametric Modulated Kernel-based Filters](https://www.isca-speech.org/archive/interspeech_2019/loweimi19_interspeech.html)”, INTERSPEECH, 2019.

15. S. Zhang, **E. Loweimi**, Y. Xu, P. Bell, and S. Renals “[Trainable Dynamic Subsampling for End-to-End Speech Recognition](https://www.isca-speech.org/archive/interspeech_2019/zhang19d_interspeech.html)”, INTERSPEECH, 2019.

16. M.A. Jalal, **E. Loweimi**, R. Moore, and T. Hain, “[Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition](https://www.isca-speech.org/archive/interspeech_2019/jalal19_interspeech.html)”, INTERSPEECH, 2019.

17. **E. Loweimi**, P. Bell, and S. Renals, “[On the Usefulness of Statistical Normalisation of Bottleneck Features for Speech Recognition](https://ieeexplore.ieee.org/document/8683330)”, ICASSP, 2019.

18. S. Zhang, **E. Loweimi**, P. Bell, and S. Renals, “[Windowed Attention Mechanisms for Speech Recognition](https://ieeexplore.ieee.org/document/8682224)”, ICASSP, 2019.

19. **E. Loweimi**, J. Barker, and T. Hain, “[On the Usefulness of the Speech Phase Spectrum for Pitch Extraction](https://www.isca-speech.org/archive/interspeech_2018/loweimi18_interspeech.html)”, INTERSPEECH, 2018.

20. **E. Loweimi**, J. Barker, and T. Hain, “[Exploring the use of Group Delay for Generalised VTS based Noise Compensation](https://ieeexplore.ieee.org/document/8462595)”, ICASSP, 2018.

21. **E. Loweimi**, J. Barker, and T. Hain, “[Channel Compensation in the Generalised Vector Taylor Series Approach to Robust ASR](https://www.isca-speech.org/archive/interspeech_2017/loweimi17b_interspeech.html)”, INTERSPEECH, 2017.

22. **E. Loweimi**, J. Barker, O. Saz Torralba, and T. Hain, “[Robust Source-Filter Separation of Speech Signal in the Phase Domain](https://www.isca-speech.org/archive/interspeech_2017/loweimi17_interspeech.html)”, INTERSPEECH, 2017.

23. **E. Loweimi**, J. Barker, and T. Hain, “[Statistical Normalisation of Phase-based Feature Representation for Robust Speech Recognition](https://ieeexplore.ieee.org/document/7953170)”, ICASSP, 2017.

24. **E. Loweimi**, J. Barker, and T. Hain, “[Use of Generalised Nonlinearity in VTS Noise Compensation for Robust Speech Recognition](https://www.isca-speech.org/archive/interspeech_2016/loweimi16_interspeech.html)”, INTERSPEECH, 2016.

25. **E. Loweimi**, J. Barker, and T. Hain, “[Source-filter Separation of Speech Signal in the Phase Domain](https://www.isca-speech.org/archive/interspeech_2015/loweimi15_interspeech.html)”, INTERSPEECH, 2015.

26. **E. Loweimi**, M. Doulaty, J. Barker, and T. Hain, “[Long-term statistical Feature Extraction from Speech Signal and its Application in Emotion Recognition](https://link.springer.com/chapter/10.1007/978-3-319-25789-1_17)”, Statistical Language and Speech Processing (SLSP), 2015.

27. **E. Loweimi**, M. Doulaty, J. Barker, and T. Hain, "[Emotion Recognition from the Speech Signal by Effective Combination of Generative and Discriminative Models](https://eprints.whiterose.ac.uk/103952/)", USES, 2015. 

27. **E. Loweimi**, J. Barker, and T. Hain, "[Compression of Model-based Group Delay Function for Robust Speech Recognition](https://eprints.whiterose.ac.uk/85055/)", USES, 2014. 

27. **E. Loweimi**, S.M. Ahadi, and T. Drugman, “[A New Phase-based Feature Representation for Robust Speech Recognition](https://ieeexplore.ieee.org/document/6639051)”, ICASSP, 2013.

28. **E. Loweimi**, S.M. Ahadi, T. Drugman, and S. Loveymi, “[On the Importance of Pre-emphasis and Window Shape in Phase-based Speech Recognition](https://link.springer.com/chapter/10.1007/978-3-642-38847-7_21)”, Lecture
Notes in Computer Science, vol. 7911 LNAI, 2013.

29. **E. Loweimi**, S.M. Ahadi, and H. Sheikhzadeh, “[Phase-only Speech Reconstruction Using Very Short Frames](https://www.isca-speech.org/archive/interspeech_2011/loweimi11_interspeech.html)”, INTERSPEECH, 2011.

30. **E. Loweimi** and S.M. Ahadi, “[A New Group Delay-based Feature for Robust Speech Recognition](https://ieeexplore.ieee.org/document/6011884)”, ICME, 2011.

31. **E. Loweimi**, S.M. Ahadi, and S. Loveymi, “[On the Importance of Phase and Magnitude Spectra in Speech Enhancement](https://ieeexplore.ieee.org/document/5955843)”, ICEE, 2011.

32. **E. Loweimi** and S.M. Ahadi, "[Objective Evaluation of Phase and Magnitude only Reconstructed Speech: New Considerations](https://ieeexplore.ieee.org/document/5605496)", ISSPA, 2010.

33. **E. Loweimi** and S.M. Ahadi, “[Objective Evaluation of Magnitude and Phase only Spectrum-based Reconstruction of the Speech Signal](https://ieeexplore.ieee.org/document/5463311)”, ISCCSP, 2010.


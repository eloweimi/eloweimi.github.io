---
layout: page
title: ""
---

## PhD Thesis ##
**E. Loweimi**, "[Robust Phase-based Speech Signal Processing: From Source-Filter Separation to Model-Based Robust ASR](https://etheses.whiterose.ac.uk/19409)" Ph.D. thesis, University of Sheffield, 2018. &nbsp; &nbsp; [PDF](https://etheses.whiterose.ac.uk/19409/1/Erfan_Loweimi_PhD_Thesis.pdf) &nbsp; &nbsp; [BibTeX](/files/others/phd-thesis.bib) &nbsp; &nbsp;

<br>

## Journals ##
1. Z. Yue, **E. Loweimi**, Z. Cvetkovic, J. Barker, and H. Christensen, “[Raw Acoustic-articulatory Multimodal Dysarthric Speech Recognition](https://www.sciencedirect.com/science/article/pii/S0885230825000646),” Computer Speech & Language, vol. 95, p. 101839, 2026, doi: 10.1016/j.csl.2025.101839
   
2. **E. Loweimi**, M. Qian, K. Knill, and M. Gales, [Speaker Retrieval in the Wild: Challenges, Effectiveness and Robustness](https://arxiv.org/pdf/2504.18950), Under Review, 2025.

3. S. Hosseini, G. Chinello, G. Lindsay, **E. Loweimi**, M. A. Ansari, and D. McGlinchey, “[Transfer Learning for Data-Driven Wet Gas Flow Metering: Enhancing Generalisation in Digital Measurement Systems](https://www.sciencedirect.com/science/article/pii/S0955598625003383?via%3Dihub),” Flow Measurement and Instrumentation, p. 103146, 2025, doi: 10.1016/j.flowmeasinst.2025.103146.

4. A. Núñez García, S. de la Fuente García, **E. Loweimi**, M. Masoodian, R. Vieira, A. Rodrigues, and S. Luz, “[A study protocol for assessing the effects of intangible cultural heritage experiences on human well-being](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0336120),” PLOS ONE, Nov. 12, 2025, doi: 10.1371/journal.pone.0336120.

5. G. Wu, A. Haider, X. Tian, **E. Loweimi**, Ch-H.Chan, M. Qian, A. Muhammad, I. Spence, R. Cooper, W. Ng, J. Kittler, M. Gales and H. Wang, "[Multi-modal Video Search by Examples – A Video Quality Impact Analysis](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cvi2.12303)", IET Computer Vision, pp. 1–17, 2024, doi: 10.1049/cvi2.12303.

6. **E. Loweimi**, A. Carmantini, P. Bell, S. Renals and Z. Cvetkovic, "[Phonetic Error Analysis Beyond Phone Error Rate](https://ieeexplore.ieee.org/abstract/document/10244118)", IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 31, pp. 3346-3361, 2023, doi: 10.1109/TASLP.2023.3313417. &nbsp; [Preprint](https://kclpure.kcl.ac.uk/ws/portalfiles/portal/229243895/LEA_PrePrint.pdf)

7. **E. Loweimi**, Z. Yue, P. Bell, S. Renals, and Z. Cvetkovic, “[Multi-stream Acoustic
Modelling using Raw Real and Imaginary Parts of the Fourier Transform](https://ieeexplore.ieee.org/abstract/document/10026604)”, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 31, pp. 876-890, 2023, doi: 10.1109/TASLP.2023.3237167. &nbsp; [Preprint](https://kclpure.kcl.ac.uk/ws/portalfiles/portal/193442046/Real_Imag_Journal_FINAL.pdf)

8. Z. Yue **<sup>&#8224;</sup>, E. Loweimi <sup>&#8224;</sup>**, J. Barker, H. Christensen, and Z. Cvetkovic, “[Acoustic
Modelling from Raw Source and Filter Components for Dysarthric Speech Recognition](https://ieeexplore.ieee.org/document/9900378)”,
 IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 30, pp. 2968-2980, 2022, doi: 10.1109/TASLP.2022.3205766 (**<sup>&#8224;</sup>** Equal contribution). &nbsp; [Preprint](https://eprints.whiterose.ac.uk/192463/6/Journal_zhengjun_Erfan__source_filter_%20%289%29.pdf)


<br>

## Conferences ##

1. Z. Yue, D. Kayande, Z. Cvetkovic, and **E. Loweimi**, [Probing Whisper for Dysarthric Speech in Detection and Assessment](https://arxiv.org/abs/2510.04219),  ICASSP, 2026 (Accepted).

2. K. Fatehi, A. Shirian, and **E. Loweimi**, [FinHuBERT: Hierarchical Feature Imitating Networks for Low-Resource Speech Recognition](https://eloweimi.github.io/publications/), ICASSP, 2026 (Accepted). 

3. **E. Loweimi**, S. De La Fonte Garcia, and S. Luz, [Zero-Shot Speech-Based Depression and Anxiety Assessment with LLMs](https://www.isca-archive.org/interspeech_2025/loweimi25_interspeech.pdf), INTERSPEECH, 2025.
  
4. Z. Yue, M. Barberis, T. Patel, J. Dineley, W. Doedens, L. Stipdonk, Y.Y. Zhang, E. de Witte, **E. Loweimi**, H. Van hamme, D. Satoer, M. Ruiter, L. Moro-Velazquez, N. Cummins, O. Scharenborg, [Challenges and Practical Guidelines for Atypical Speech Data Collection, Annotation, Usage and Sharing: A Multi-project Perspective](https://www.isca-archive.org/interspeech_2025/yue25_interspeech.pdf), INTERSPEECH, 2025.

5. **E. Loweimi**, M. Qian, K. Knill, and M. Gales, [On the Usefulness of Speaker Embeddings for Speaker Retrieval in the Wild:
A Comparative Study of x-vector and ECAPA-TDNN Models](https://www.isca-archive.org/interspeech_2024/loweimi24_interspeech.html), INTERSPEECH, 2024.

6. M. Qian, R. Ma, A. Liusie, **E. Loweimi**, K. Knill, and M. Gales, [Zero-shot Audio Topic Reranking using Large Language Models](https://arxiv.org/pdf/2309.07606), SLT, 2024.

7. **E. Loweimi**, A. Carmantini, P. Bell, S. Renals, and Z. Cvetkovic, “[Phonetic Error Analysis of Raw Waveform Acoustic Models with Parametric and Non-Parametric CNNs](https://arxiv.org/abs/2406.00898)", arXiv, 2024.

8. Z. Yue **<sup>&#8224;</sup>, E. Loweimi <sup>&#8224;</sup>**, and Z. Cvetkovic, “[Dysarthric Speech Recognition, Detection and Classification using Raw Phase and Magnitude Spectra](https://www.isca-speech.org/archive/interspeech_2023/yue23_interspeech.html)“, INTERSPEECH, 2023 (**<sup>&#8224;</sup>** Equal contribution).

9. Z. Yue **<sup>&#8224;</sup>, E. Loweimi <sup>&#8224;</sup>**, J. Barker, H. Christensen, and Z. Cvetkovic, “[Dysarthric Speech Recognition from Raw Waveform with Parametric CNNs](https://www.isca-speech.org/archive/interspeech_2022/yue22_interspeech.html)”, INTERSPEECH,
2022 (**<sup>&#8224;</sup>** Equal contribution).

10. N. Shao, **E. Loweimi**, and X. Li, “[RCT: Random Consistency Training for Semisupervised Sound Event Detection](https://www.isca-speech.org/archive/interspeech_2022/shao22_interspeech.html)”, INTERSPEECH, 2022.

11. Z. Yue **<sup>&#8224;</sup>, E. Loweimi<sup>&#8224;</sup>**, and Z. Cvetkovic, “[Raw Source and Filter Modelling for Dysarthric Speech Recognition](https://ieeexplore.ieee.org/document/9746553)”, ICASSP, 2022 (**<sup>&#8224;</sup>** Equal contribution).

12. Z. Yue, **E. Loweimi**, Z. Cvetkovic, H. Christensen, and J. Barker, “[Multimodal Acoustic-Articulatory Feature Fusion for Dysarthric Speech Recognition](https://ieeexplore.ieee.org/document/9746855)”, ICASSP, 2022.

13. **E. Loweimi**, P. Bell, and S. Renals, “[Speech Acoustic Modelling using Raw Source and Filter Components](https://www.isca-speech.org/archive/interspeech_2021/loweimi21_interspeech.html)”, INTERSPEECH, 2021.

14. S. Zhang, **E. Loweimi**, P. Bell, and S. Renals, “[Stochastic Attention Head Removal: A Simple and Effective Method for Improving Transformer Based ASR
Models](https://www.isca-speech.org/archive/interspeech_2021/zhang21p_interspeech.html)”, INTERSPEECH, 2021.

15. **E. Loweimi**, Z. Cvetkovic, P. Bell, and S. Renals, “[Speech Acoustic Modelling from Raw Phase Spectrum](https://ieeexplore.ieee.org/document/9413727)”, ICASSP, 2021.

16. S. Zhang, C-T. Do, R. Doddipatla, **E. Loweimi**, P. Bell, and S. Renals, “[Train Your Classifier First: Cascade Neural Networks Training from Upper Layers to Lower Layers](https://ieeexplore.ieee.org/document/9413565)”, ICASSP, 2021.

17. **E. Loweimi**, P. Bell, and S. Renals, “[Raw Sign and Magnitude Spectra for Multihead Acoustic Modelling](https://www.isca-speech.org/archive/interspeech_2020/loweimi20b_interspeech.html)”, INTERSPEECH, 2020.

18. **E. Loweimi**, P. Bell, and S. Renals, “[On the Robustness and Training Dynamics of Raw Waveform Models](https://www.isca-speech.org/archive/interspeech_2020/loweimi20_interspeech.html)”, INTERSPEECH, 2020.

19. S. Zhang, **E. Loweimi**, P. Bell, and S. Renals, “[On The Usefulness of Self-Attention for Automatic Speech Recognition with Transformers](https://ieeexplore.ieee.org/abstract/document/9383521)”, SLT, 2020.

20. J. Fainberg, O. Klejch, **E. Loweimi**, P. Bell, and S. Renals, “[Acoustic Model Adaptation from Raw Waveforms with SincNet](https://ieeexplore.ieee.org/document/9003974)”, ASRU, 2019.

21. **E. Loweimi**, P. Bell, and S. Renals, “[On Learning Interpretable CNNs with Parametric Modulated Kernel-based Filters](https://www.isca-speech.org/archive/interspeech_2019/loweimi19_interspeech.html)”, INTERSPEECH, 2019.
    
22. S. Zhang, **E. Loweimi**, Y. Xu, P. Bell, and S. Renals “[Trainable Dynamic Subsampling for End-to-End Speech Recognition](https://www.isca-speech.org/archive/interspeech_2019/zhang19d_interspeech.html)”, INTERSPEECH, 2019.

23. M.A. Jalal, **E. Loweimi**, R. Moore, and T. Hain, “[Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition](https://www.isca-speech.org/archive/interspeech_2019/jalal19_interspeech.html)”, INTERSPEECH, 2019.

24. **E. Loweimi**, P. Bell, and S. Renals, “[On the Usefulness of Statistical Normalisation of Bottleneck Features for Speech Recognition](https://ieeexplore.ieee.org/document/8683330)”, ICASSP, 2019.

25. S. Zhang, **E. Loweimi**, P. Bell, and S. Renals, “[Windowed Attention Mechanisms for Speech Recognition](https://ieeexplore.ieee.org/document/8682224)”, ICASSP, 2019.

26. **E. Loweimi**, J. Barker, and T. Hain, “[On the Usefulness of the Speech Phase Spectrum for Pitch Extraction](https://www.isca-speech.org/archive/interspeech_2018/loweimi18_interspeech.html)”, INTERSPEECH, 2018.

27. **E. Loweimi**, J. Barker, and T. Hain, “[Exploring the use of Group Delay for Generalised VTS based Noise Compensation](https://ieeexplore.ieee.org/document/8462595)”, ICASSP, 2018.

28. **E. Loweimi**, J. Barker, and T. Hain, “[Channel Compensation in the Generalised Vector Taylor Series Approach to Robust ASR](https://www.isca-speech.org/archive/interspeech_2017/loweimi17b_interspeech.html)”, INTERSPEECH, 2017.

29. **E. Loweimi**, J. Barker, O. Saz Torralba, and T. Hain, “[Robust Source-Filter Separation of Speech Signal in the Phase Domain](https://www.isca-speech.org/archive/interspeech_2017/loweimi17_interspeech.html)”, INTERSPEECH, 2017.

30. **E. Loweimi**, J. Barker, and T. Hain, “[Statistical Normalisation of Phase-based Feature Representation for Robust Speech Recognition](https://ieeexplore.ieee.org/document/7953170)”, ICASSP, 2017.

31. **E. Loweimi**, J. Barker, and T. Hain, “[Use of Generalised Nonlinearity in VTS Noise Compensation for Robust Speech Recognition](https://www.isca-speech.org/archive/interspeech_2016/loweimi16_interspeech.html)”, INTERSPEECH, 2016.

32. **E. Loweimi**, J. Barker, and T. Hain, “[Source-filter Separation of Speech Signal in the Phase Domain](https://www.isca-speech.org/archive/interspeech_2015/loweimi15_interspeech.html)”, INTERSPEECH, 2015.

33. **E. Loweimi**, M. Doulaty, J. Barker, and T. Hain, “[Long-term statistical Feature Extraction from Speech Signal and its Application in Emotion Recognition](https://link.springer.com/chapter/10.1007/978-3-319-25789-1_17)”, Statistical Language and Speech Processing (SLSP), 2015.

34. **E. Loweimi**, M. Doulaty, J. Barker, and T. Hain, "[Emotion Recognition from the Speech Signal by Effective Combination of Generative and Discriminative Models](https://eprints.whiterose.ac.uk/103952/)", USES, 2015. 

35. **E. Loweimi**, J. Barker, and T. Hain, "[Compression of Model-based Group Delay Function for Robust Speech Recognition](https://eprints.whiterose.ac.uk/85055/)", USES, 2014. 

36. **E. Loweimi**, S.M. Ahadi, and T. Drugman, “[A New Phase-based Feature Representation for Robust Speech Recognition](https://ieeexplore.ieee.org/document/6639051)”, ICASSP, 2013.

37. **E. Loweimi**, S.M. Ahadi, T. Drugman, and S. Loveymi, “[On the Importance of Pre-emphasis and Window Shape in Phase-based Speech Recognition](https://link.springer.com/chapter/10.1007/978-3-642-38847-7_21)”, Lecture
Notes in Computer Science, vol. 7911 LNAI, 2013.

38. **E. Loweimi**, S.M. Ahadi, and H. Sheikhzadeh, “[Phase-only Speech Reconstruction Using Very Short Frames](https://www.isca-speech.org/archive/interspeech_2011/loweimi11_interspeech.html)”, INTERSPEECH, 2011.

39. **E. Loweimi** and S.M. Ahadi, “[A New Group Delay-based Feature for Robust Speech Recognition](https://ieeexplore.ieee.org/document/6011884)”, ICME, 2011.

40. **E. Loweimi**, S.M. Ahadi, and S. Loveymi, “[On the Importance of Phase and Magnitude Spectra in Speech Enhancement](https://ieeexplore.ieee.org/document/5955843)”, ICEE, 2011 ([PDF](/files/others/ICEE2011.pdf)). 

41. **E. Loweimi** and S.M. Ahadi, "[Objective Evaluation of Phase and Magnitude only Reconstructed Speech: New Considerations](https://ieeexplore.ieee.org/document/5605496)", ISSPA, 2010.

42. **E. Loweimi** and S.M. Ahadi, “[Objective Evaluation of Magnitude and Phase only Spectrum-based Reconstruction of the Speech Signal](https://ieeexplore.ieee.org/document/5463311)”, ISCCSP, 2010.

---
layout: page
title: ""
---

## PhD Thesis ##
**E. Loweimi**, "[Robust Phase-based Speech Signal Processing: From Source-Filter Separation to Model-Based Robust ASR](https://etheses.whiterose.ac.uk/19409)" Ph.D. thesis, University of Sheffield, 2018. &nbsp; &nbsp; [PDF](https://etheses.whiterose.ac.uk/19409/1/Erfan_Loweimi_PhD_Thesis.pdf) &nbsp; &nbsp; [BibTeX](/files/others/phd-thesis.bib) &nbsp; &nbsp;

<br>

## Journals ##
1. **E. Loweimi**, M. Qian, K. Knill, and M. Gales, [Speaker Retrieval in the Wild: Challenges, Effectiveness and Robustness ](https://arxiv.org/pdf/2504.18950),  arXiv (Under review), 2025.

2. G. Wu, A. Haider, X. Tian, **E. Loweimi**, Ch-H.Chan, M. Qian, A. Muhammad, I. Spence, R. Cooper, W. Ng, J. Kittler, M. Gales and H. Wang, "[Multi-modal Video Search by Examples – A Video Quality Impact Analysis](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cvi2.12303)", IET Computer Vision, pp. 1–17, 2024, doi: 10.1049/cvi2.12303.

3. **E. Loweimi**, A. Carmantini, P. Bell, S. Renals and Z. Cvetkovic, "[Phonetic Error Analysis Beyond Phone Error Rate](https://ieeexplore.ieee.org/abstract/document/10244118)", IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 31, pp. 3346-3361, 2023, doi: 10.1109/TASLP.2023.3313417. &nbsp; [Preprint](https://kclpure.kcl.ac.uk/ws/portalfiles/portal/229243895/LEA_PrePrint.pdf)

4. **E. Loweimi**, Z. Yue, P. Bell, S. Renals, and Z. Cvetkovic, “[Multi-stream Acoustic
Modelling using Raw Real and Imaginary Parts of the Fourier Transform](https://ieeexplore.ieee.org/abstract/document/10026604)”, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 31, pp. 876-890, 2023, doi: 10.1109/TASLP.2023.3237167. &nbsp; [Preprint](https://kclpure.kcl.ac.uk/ws/portalfiles/portal/193442046/Real_Imag_Journal_FINAL.pdf)

5. Z. Yue **<sup>&#8224;</sup>, E. Loweimi <sup>&#8224;</sup>**, J. Barker, H. Christensen, and Z. Cvetkovic, “[Acoustic
Modelling from Raw Source and Filter Components for Dysarthric Speech Recognition](https://ieeexplore.ieee.org/document/9900378)”,
 IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 30, pp. 2968-2980, 2022, doi: 10.1109/TASLP.2022.3205766 (**<sup>&#8224;</sup>** Equal contribution). &nbsp; [Preprint](https://eprints.whiterose.ac.uk/192463/6/Journal_zhengjun_Erfan__source_filter_%20%289%29.pdf)

<br>

## Conferences ##

1. **E. Loweimi**, M. Qian, K. Knill, and M. Gales, [On the Usefulness of Speaker Embeddings for Speaker Retrieval in the Wild:
A Comparative Study of x-vector and ECAPA-TDNN Models](https://www.isca-archive.org/interspeech_2024/loweimi24_interspeech.html), INTERSPEECH, 2024.

2. M. Qian, R. Ma, A. Liusie, **E. Loweimi**, K. Knill, and M. Gales, [Zero-shot Audio Topic Reranking using Large Language Models](https://arxiv.org/pdf/2309.07606), SLT, 2024.

3. **E. Loweimi**, A. Carmantini, P. Bell, S. Renals, and Z. Cvetkovic, “[Phonetic Error Analysis of Raw Waveform Acoustic Models with Parametric and Non-Parametric CNNs](https://arxiv.org/abs/2406.00898)", arXiv, 2024.

4. Z. Yue **<sup>&#8224;</sup>, E. Loweimi <sup>&#8224;</sup>**, and Z. Cvetkovic, “[Dysarthric Speech Recognition, Detection and Classification using Raw Phase and Magnitude Spectra](https://www.isca-speech.org/archive/interspeech_2023/yue23_interspeech.html)“, INTERSPEECH, 2023 (**<sup>&#8224;</sup>** Equal contribution).

5. Z. Yue **<sup>&#8224;</sup>, E. Loweimi <sup>&#8224;</sup>**, J. Barker, H. Christensen, and Z. Cvetkovic, “[Dysarthric Speech Recognition from Raw Waveform with Parametric CNNs](https://www.isca-speech.org/archive/interspeech_2022/yue22_interspeech.html)”, INTERSPEECH,
2022 (**<sup>&#8224;</sup>** Equal contribution).

6. N. Shao, **E. Loweimi**, and X. Li, “[RCT: Random Consistency Training for Semisupervised Sound Event Detection](https://www.isca-speech.org/archive/interspeech_2022/shao22_interspeech.html)”, INTERSPEECH, 2022.

7. Z. Yue **<sup>&#8224;</sup>, E. Loweimi<sup>&#8224;</sup>**, and Z. Cvetkovic, “[Raw Source and Filter Modelling for Dysarthric Speech Recognition](https://ieeexplore.ieee.org/document/9746553)”, ICASSP, 2022 (**<sup>&#8224;</sup>** Equal contribution).

8. Z. Yue, **E. Loweimi**, Z. Cvetkovic, H. Christensen, and J. Barker, “[Multimodal Acoustic-Articulatory Feature Fusion for Dysarthric Speech Recognition](https://ieeexplore.ieee.org/document/9746855)”, ICASSP, 2022.

9. **E. Loweimi**, P. Bell, and S. Renals, “[Speech Acoustic Modelling using Raw Source and Filter Components](https://www.isca-speech.org/archive/interspeech_2021/loweimi21_interspeech.html)”, INTERSPEECH, 2021.

10. S. Zhang, **E. Loweimi**, P. Bell, and S. Renals, “[Stochastic Attention Head Removal: A Simple and Effective Method for Improving Transformer Based ASR
Models](https://www.isca-speech.org/archive/interspeech_2021/zhang21p_interspeech.html)”, INTERSPEECH, 2021.

11. **E. Loweimi**, Z. Cvetkovic, P. Bell, and S. Renals, “[Speech Acoustic Modelling from Raw Phase Spectrum](https://ieeexplore.ieee.org/document/9413727)”, ICASSP, 2021.

12. S. Zhang, C-T. Do, R. Doddipatla, **E. Loweimi**, P. Bell, and S. Renals, “[Train Your Classifier First: Cascade Neural Networks Training from Upper Layers to Lower Layers](https://ieeexplore.ieee.org/document/9413565)”, ICASSP, 2021.

13. **E. Loweimi**, P. Bell, and S. Renals, “[Raw Sign and Magnitude Spectra for Multihead Acoustic Modelling](https://www.isca-speech.org/archive/interspeech_2020/loweimi20b_interspeech.html)”, INTERSPEECH, 2020.

14. **E. Loweimi**, P. Bell, and S. Renals, “[On the Robustness and Training Dynamics of Raw Waveform Models](https://www.isca-speech.org/archive/interspeech_2020/loweimi20_interspeech.html)”, INTERSPEECH, 2020.

15. S. Zhang, **E. Loweimi**, P. Bell, and S. Renals, “[On The Usefulness of Self-Attention for Automatic Speech Recognition with Transformers](https://ieeexplore.ieee.org/abstract/document/9383521)”, SLT, 2020.

16. J. Fainberg, O. Klejch, **E. Loweimi**, P. Bell, and S. Renals, “[Acoustic Model Adaptation from Raw Waveforms with SincNet](https://ieeexplore.ieee.org/document/9003974)”, ASRU, 2019.

17. **E. Loweimi**, P. Bell, and S. Renals, “[On Learning Interpretable CNNs with Parametric Modulated Kernel-based Filters](https://www.isca-speech.org/archive/interspeech_2019/loweimi19_interspeech.html)”, INTERSPEECH, 2019.

18. S. Zhang, **E. Loweimi**, Y. Xu, P. Bell, and S. Renals “[Trainable Dynamic Subsampling for End-to-End Speech Recognition](https://www.isca-speech.org/archive/interspeech_2019/zhang19d_interspeech.html)”, INTERSPEECH, 2019.

19. M.A. Jalal, **E. Loweimi**, R. Moore, and T. Hain, “[Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition](https://www.isca-speech.org/archive/interspeech_2019/jalal19_interspeech.html)”, INTERSPEECH, 2019.

20. **E. Loweimi**, P. Bell, and S. Renals, “[On the Usefulness of Statistical Normalisation of Bottleneck Features for Speech Recognition](https://ieeexplore.ieee.org/document/8683330)”, ICASSP, 2019.

21. S. Zhang, **E. Loweimi**, P. Bell, and S. Renals, “[Windowed Attention Mechanisms for Speech Recognition](https://ieeexplore.ieee.org/document/8682224)”, ICASSP, 2019.

22. **E. Loweimi**, J. Barker, and T. Hain, “[On the Usefulness of the Speech Phase Spectrum for Pitch Extraction](https://www.isca-speech.org/archive/interspeech_2018/loweimi18_interspeech.html)”, INTERSPEECH, 2018.

23. **E. Loweimi**, J. Barker, and T. Hain, “[Exploring the use of Group Delay for Generalised VTS based Noise Compensation](https://ieeexplore.ieee.org/document/8462595)”, ICASSP, 2018.

24. **E. Loweimi**, J. Barker, and T. Hain, “[Channel Compensation in the Generalised Vector Taylor Series Approach to Robust ASR](https://www.isca-speech.org/archive/interspeech_2017/loweimi17b_interspeech.html)”, INTERSPEECH, 2017.

25. **E. Loweimi**, J. Barker, O. Saz Torralba, and T. Hain, “[Robust Source-Filter Separation of Speech Signal in the Phase Domain](https://www.isca-speech.org/archive/interspeech_2017/loweimi17_interspeech.html)”, INTERSPEECH, 2017.

26. **E. Loweimi**, J. Barker, and T. Hain, “[Statistical Normalisation of Phase-based Feature Representation for Robust Speech Recognition](https://ieeexplore.ieee.org/document/7953170)”, ICASSP, 2017.

27. **E. Loweimi**, J. Barker, and T. Hain, “[Use of Generalised Nonlinearity in VTS Noise Compensation for Robust Speech Recognition](https://www.isca-speech.org/archive/interspeech_2016/loweimi16_interspeech.html)”, INTERSPEECH, 2016.

28. **E. Loweimi**, J. Barker, and T. Hain, “[Source-filter Separation of Speech Signal in the Phase Domain](https://www.isca-speech.org/archive/interspeech_2015/loweimi15_interspeech.html)”, INTERSPEECH, 2015.

29. **E. Loweimi**, M. Doulaty, J. Barker, and T. Hain, “[Long-term statistical Feature Extraction from Speech Signal and its Application in Emotion Recognition](https://link.springer.com/chapter/10.1007/978-3-319-25789-1_17)”, Statistical Language and Speech Processing (SLSP), 2015.

30. **E. Loweimi**, M. Doulaty, J. Barker, and T. Hain, "[Emotion Recognition from the Speech Signal by Effective Combination of Generative and Discriminative Models](https://eprints.whiterose.ac.uk/103952/)", USES, 2015. 

31. **E. Loweimi**, J. Barker, and T. Hain, "[Compression of Model-based Group Delay Function for Robust Speech Recognition](https://eprints.whiterose.ac.uk/85055/)", USES, 2014. 

32. **E. Loweimi**, S.M. Ahadi, and T. Drugman, “[A New Phase-based Feature Representation for Robust Speech Recognition](https://ieeexplore.ieee.org/document/6639051)”, ICASSP, 2013.

33. **E. Loweimi**, S.M. Ahadi, T. Drugman, and S. Loveymi, “[On the Importance of Pre-emphasis and Window Shape in Phase-based Speech Recognition](https://link.springer.com/chapter/10.1007/978-3-642-38847-7_21)”, Lecture
Notes in Computer Science, vol. 7911 LNAI, 2013.

34. **E. Loweimi**, S.M. Ahadi, and H. Sheikhzadeh, “[Phase-only Speech Reconstruction Using Very Short Frames](https://www.isca-speech.org/archive/interspeech_2011/loweimi11_interspeech.html)”, INTERSPEECH, 2011.

35. **E. Loweimi** and S.M. Ahadi, “[A New Group Delay-based Feature for Robust Speech Recognition](https://ieeexplore.ieee.org/document/6011884)”, ICME, 2011.

36. **E. Loweimi**, S.M. Ahadi, and S. Loveymi, “[On the Importance of Phase and Magnitude Spectra in Speech Enhancement](https://ieeexplore.ieee.org/document/5955843)”, ICEE, 2011.

37. **E. Loweimi** and S.M. Ahadi, "[Objective Evaluation of Phase and Magnitude only Reconstructed Speech: New Considerations](https://ieeexplore.ieee.org/document/5605496)", ISSPA, 2010.

38. **E. Loweimi** and S.M. Ahadi, “[Objective Evaluation of Magnitude and Phase only Spectrum-based Reconstruction of the Speech Signal](https://ieeexplore.ieee.org/document/5463311)”, ISCCSP, 2010.
